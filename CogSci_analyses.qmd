---
title: "Nils Wendel Heinrich: Distant Fixations - action goals"
subtitle: "Moonlander I - Analysis for CogSci submission"
author: "Nils Wendel Heinrich"
date: "2024-01-21"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
editor_options:
  chunk_output_type: console
jupyter: julia-1.9
---

# Setup

## Packages

```{julia}
#| label: packages

using Arrow
using AlgebraOfGraphics
using CairoMakie
using DataFrames
using DataFrameMacros
using MixedModels
using MixedModelsMakie
using Random
#using RCall

CairoMakie.activate!(; type="svg");
```

```{julia}
#| label: constants
const RNG = MersenneTwister(36)
N_iterations = 10000

const AoG = AlgebraOfGraphics;
```

# Modeling visual exploration
Visual exploration might reflect exploring the action field (Kahl et al., 2022) that consists of perceived action possibilities (Gibson, 1966). We hypothesize that the visual environment is explored in a smaller radius when motor control efficiency is reduced. Therefore we will feed *all* fixations in a model predicting distance to agent that includes input noise as categorical covariate (and N_visible_obstacles as numerical covariate).

## Data
```{julia}
#| label: data

all_fixations = DataFrame(Arrow.Table("data/Experiment1_FixationsComplete.arrow"))
all_fixations = dropmissing(all_fixations, [:N_visible_obstacles, :N_visible_drift_tiles])

# Filtering saccades with no amplitude
all_fixations = all_fixations[(all_fixations.fixation_duration .>= 0.06), :]

describe(all_fixations)
size(all_fixations)  # 67794 rows
```

```{julia}
hypothesis_coding = Dict(
  :ID => Grouping(),
  :total_control_loss => Grouping(),
  :N_visible_drift_tiles => Grouping(),
  :input_noise => HypothesisCoding(
    [
      -1 +1 0
      0 -1 +1
    ];
    levels=["N", "W", "S"],
    labels=["weak-none", "strong-weak"],
  ),
);
```

```{julia}
#| label: pred_visExplore_1

pred_visExplore_1 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 | N_visible_drift_tiles)
    + (1 | ID));
    fit(MixedModel, formula, all_fixations; contrasts=hypothesis_coding);
  end

issingular(pred_visExplore_1)  # NOT overparameterized
```

```{julia}
#| label: pred_visExplore_2

pred_visExplore_2 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 + input_noise | N_visible_drift_tiles)
    + (1 + input_noise | ID));
    fit(MixedModel, formula, all_fixations; contrasts=hypothesis_coding);
  end

issingular(pred_visExplore_2)  # overparameterized
```

```{julia}
#| label: pred_visExplore_3

pred_visExplore_3 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 + N_visible_obstacles | N_visible_drift_tiles)
    + (1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, all_fixations; contrasts=hypothesis_coding);
  end

issingular(pred_visExplore_3)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:pred_visExplore_1, :pred_visExplore_3]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(pred_visExplore_1, pred_visExplore_3)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end
```
Referring to BIC (or AIC), the model with N_visible_obstacles as random slope effect wins.

Stating zerocorr
```{julia}
#| label: pred_visExplore_3_zc

pred_visExplore_3_zc = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + zerocorr(1 + N_visible_obstacles | N_visible_drift_tiles)
    + zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, all_fixations; contrasts=hypothesis_coding);
  end

issingular(pred_visExplore_3_zc)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:pred_visExplore_3, :pred_visExplore_3_zc]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(pred_visExplore_3, pred_visExplore_3_zc)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end
```
Zerocorr is mildly better. Will proceed using pred_visExplore_3_zc.

### Model selection
```{julia}
#| label: pred_visExplore_3_zc

pred_visExplore_3_zc = let
    formula = @formula(log(distance_to_spaceship) ~ 1 + N_visible_obstacles + input_noise 
    + zerocorr(1 + N_visible_obstacles | N_visible_drift_tiles)
    + zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, all_fixations; contrasts=hypothesis_coding);
  end

issingular(pred_visExplore_3_zc) # NOT overparameterized

```

```{julia}
MixedModels.PCA(pred_visExplore_3_zc)
```

### Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects
#| label: fig-cm_visExplore_3_zc
#|
cm_visExplore_3_zc = first(ranefinfo(pred_visExplore_3_zc));
caterpillar!(Figure(; resolution=(800, 1200)), cm_visExplore_3_zc; orderby=1)
```

### Shrinkage plot
```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), pred_visExplore_3_zc)

```

### Bootstrapping
```{julia}
samples_predVisExplore = parametricbootstrap(RNG, N_iterations, pred_visExplore_3_zc)
tbl = samples_predVisExplore.tbl
```

Let's first take a look into the bounds
```{julia}
confint(samples_predVisExplore)
```

```{julia}
ridgeplot(samples_predVisExplore; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to agent (all fixations)")
```
Results:
- N_visible_obstacles [-0.211358, 0.0532378] X no effect
- input_noise:weak vs. none [-0.308427, -0.103417]
- input_noise:strong vs. weak [0.374834, 0.586183]

on log-scale:
- N_visible_obstacles [ -0.0279565, 0.025624] X no effect
- input_noise:weak vs. none [-0.0358762, -0.0075744]
- input_noise:strong vs. weak [0.000408187, 0.0299594]

# Modeling spatial allocation of distant fixations
Only including fixations that are 5 visual degrees away from spaceship.

## Data
```{julia}
#| label: data

my_data = DataFrame(Arrow.Table("data/Experiment1_DistantFixations.arrow"))
my_data = dropmissing(my_data, [:N_visible_obstacles, :N_visible_drift_tiles])

# Filtering fixations with duration less than 25 samples
# fixdur >= 0.0125
my_data = my_data[(my_data.fixation_duration .>= 0.06), :]

describe(my_data)
#size(my_data)  # 42315 rows
```

### Contrasts
We will declare **N_visible_drift_tiles*** as grouping variable to exclude variance caused by the visual environment. **ID** and **total_control_loss** are also grouping variables that will be explored.
We specify the contrasts for **input_noise**.

### Hypothesis Coding
```{julia}
my_cake = Dict(
  :ID => Grouping(),
  :total_control_loss => Grouping(),
  :N_visible_drift_tiles => Grouping(),
  :input_noise => HypothesisCoding(
    [
      -1 +1 0
      0 -1 +1
    ];
    levels=["N", "W", "S"],
    labels=["weak-none", "strong-weak"],
  ),
);
```

## Modeling distance to spaceship
```{julia}
#| label: pred_distAgent_1

pred_distAgent_1 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 | N_visible_drift_tiles)
    + (1 | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distAgent_1)  # NOT overparameterized
```

```{julia}
#| label: pred_distAgent_2

pred_distAgent_2 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 + input_noise | N_visible_drift_tiles)
    + (1 + input_noise | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distAgent_2)  # overparameterized
```

```{julia}
#| label: pred_distAgent_3

pred_distAgent_3 = let
    formula = @formula(distance_to_spaceship ~ 1 + N_visible_obstacles + input_noise 
    + (1 + N_visible_obstacles | N_visible_drift_tiles)
    + (1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distAgent_3)  # overparameterized
```

### Model selection
```{julia}
#| label: pred_distAgent_1

pred_distAgent_1 = let
    formula = @formula(log(distance_to_spaceship) ~ 1 + N_visible_obstacles + input_noise 
    + (1 | N_visible_drift_tiles)
    + (1 | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distAgent_1) # NOT overparameterized

```

### Bootstrapping
```{julia}
samples_pred_DistAgent = parametricbootstrap(RNG, N_iterations, pred_distAgent_1)
tbl = samples_pred_DistAgent.tbl
```

```{julia}
confint(samples_pred_DistAgent)
```

```{julia}
ridgeplot(samples_pred_DistAgent; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to agent (distant fixations)")
```
Replicated effects from visual exploration, but also found effect for **N_visible_obstacles** (complexity of visual environment) decreasing distance to agent.
Results:
- N_visible_obstacles [-0.116628, -0.0822677]
- input_noise:weak vs. none [-0.435594, -0.15973]
- input_noise:strong vs. weak [0.4511, 0.73566]

on log-scale:
- N_visible_obstacles [-0.012224, -0.0100155]
- input_noise:weak vs. none [-0.0340066, -0.0163282]
- input_noise:strong vs. weak [0.0288485, 0.0470953]

## Modeling distance to nearest obstacle
Here we have to control for variance caused by the varying number of obstacles on screen. We will therefore enter N_visible_obstacles as random intercept into the model.
```{julia}
#| label: pred_distObstacle_1

pred_distObstacle_1 = let
    formula = @formula(log(Dist_to_closest_obstacles) ~ 1 + input_noise
    + (1 | N_visible_obstacles) 
    + (1 | N_visible_drift_tiles)
    + (1 | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distObstacle_1)  # NOT overparameterized
```

```{julia}
#| label: pred_distObstacle_2

pred_distObstacle_2 = let
    formula = @formula(log(Dist_to_closest_obstacles) ~ 1 + input_noise
    + (1 + input_noise | N_visible_obstacles)  
    + (1 + input_noise | N_visible_drift_tiles)
    + (1 + input_noise | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distObstacle_2)  # overparameterized
```

### Model selection
```{julia}
#| label: pred_distObstacle_1

pred_distObstacle_1 = let
    formula = @formula(log(Dist_to_closest_obstacles) ~ 1 + input_noise
    + (1 | N_visible_obstacles) 
    + (1 | N_visible_drift_tiles)
    + (1 | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_distObstacle_1)  # NOT overparameterized

```

### Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for selected model
#| label: fig-pred_distObstacle_3_zc
#|
cm_distObstacle_1 = first(ranefinfo(pred_distObstacle_1));
caterpillar!(Figure(; resolution=(800, 1200)), cm_distObstacle_1; orderby=1)
```

### Shrinkage plot
No random slopes specified...

### Bootstrapping
```{julia}
samples_predDistObs = parametricbootstrap(RNG, N_iterations, pred_distObstacle_1)
tbl = samples_predDistObs.tbl
```

Let's first take a look into the bounds
```{julia}
confint(samples_predDistObs)
```

```{julia}
ridgeplot(samples_predDistObs; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Distance to closest obstacle (distant fixations)")
```
Results:
- input_noise:weak vs. none [-0.00819449, 0.0107502] X
- input_noise:strong vs. weak [-0.0121111, 0.00741021] X

**Investigating abandoning action goals by means of fixation duration**

## Modeling fixation duration
```{julia}
#| label: pred_fixDur_1

pred_fixDur_1 = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + (1 | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_1)  # NOT overparameterized
```

```{julia}
#| label: pred_fixDur_1_1

pred_fixDur_1_1 = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + (1 | N_visible_drift_tiles));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_1_1)  # NOT overparameterized
```

```{julia}
pred_fixDur_1
```
           Column     Variance Std.Dev.  
ID       (Intercept)  0.074242 0.272473
Residual              0.441570 0.664508

```{julia}
pred_fixDur_1_1
```
            Column    Variance Std.Dev. 
ID       (Intercept)  0.074242 0.272473
Residual              0.441570 0.664508

Sticking to pred_fixDur_1 with higher explained variance (higher ICC for ID vs. N_visible_drift_tiles)

```{julia}
#| label: pred_fixDur_2

pred_fixDur_2 = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + (1 + input_noise | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_2)  # NOT overparameterized
```

```{julia}
#| label: pred_fixDur_3

pred_fixDur_3 = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + (1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_3)  # NOT overparameterized
```

```{julia}
#| label: pred_fixDur_4

pred_fixDur_4 = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + (1 + drift_tile_onset | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_4)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:pred_fixDur_1, :pred_fixDur_2, :pred_fixDur_3, :pred_fixDur_4]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(pred_fixDur_1, pred_fixDur_2, pred_fixDur_3, pred_fixDur_4)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end
```
Referring to BIC (or AIC), pred_fixDur_3 including N_visible_obstacles as random slope effect best fits the data.

```{julia}
#| label: pred_fixDur_3_zc

pred_fixDur_3_zc = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_3_zc)  # NOT overparameterized
```

```{julia}

gof_summary = let
  nms = [:pred_fixDur_3, :pred_fixDur_3_zc]
  mods = eval.(nms)
  lrt = MixedModels.likelihoodratiotest(pred_fixDur_3, pred_fixDur_3_zc)
  DataFrame(;
    name = nms, 
    dof=dof.(mods),
    deviance=round.(deviance.(mods), digits=0),
    AIC=round.(aic.(mods),digits=0),
    AICc=round.(aicc.(mods),digits=0),
    BIC=round.(bic.(mods),digits=0),
    χ²=vcat(:., round.(lrt.tests.deviancediff, digits=0)),
    χ²_dof=vcat(:., round.(lrt.tests.dofdiff, digits=0)),
    pvalue=vcat(:., round.(lrt.tests.pvalues, digits=3))
  )
end
```
Stating zerocorr is favored by BIC (and AIC). Proceed with pred_fixDur_3_zc.

### Model selection
```{julia}
#| label: pred_fixDur_3_zc

pred_fixDur_3_zc = let
    formula = @formula(log(fixation_duration) ~ 1 + N_visible_obstacles + input_noise + drift_tile_onset
    + zerocorr(1 + N_visible_obstacles | ID));
    fit(MixedModel, formula, my_data; contrasts=my_cake);
  end

issingular(pred_fixDur_3_zc)  # NOT overparameterized

```

### Caterpillar plot
We can visually verify having stated zero correlation between random effects.
```{julia}
#| fig-cap1: Prediction intervals on subject random effects for selected model
#| label: fig-pred_distObstacle_3_zc
#|
cm_fixDur_3_zc = first(ranefinfo(pred_fixDur_3_zc));
caterpillar!(Figure(; resolution=(800, 1200)), cm_fixDur_3_zc; orderby=1)
```

### Shrinkage plot
```{julia}
#| code-fold: true
#| label: fig-shrinkage
#|
#| fig-cap: Shrinkage plots of the subject random effects in the chosen model
shrinkageplot!(Figure(; resolution=(1000, 1200)), pred_fixDur_3_zc)

```

### Bootstrapping
```{julia}
samples_predFixDur = parametricbootstrap(RNG, N_iterations, pred_fixDur_3_zc)
tbl = samples_predFixDur.tbl
```

Let's first take a look into the bounds
```{julia}
confint(samples_predFixDur)
```

```{julia}
ridgeplot(samples_predFixDur; show_intercept=false, xlabel="Bootstrap density and 95%CI", title="Fixation duration (distant fixations)")
```
Results:
- N_visible_obstacles [0.00541627, 0.0207796]
- input_noise:weak vs. none [-0.00642773, 0.0241418] X
- input_noise:strong vs. weak [-0.0353359, -0.0041089]
- drift_tile_onset [0.426046, 0.514824]

